{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rel-Trial Data Export\n",
    "\n",
    "This notebook exports the rel-trial tables from SQLite database to CSV files for use in RML mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from relbench.datasets import get_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from C:\\Users\\anils\\AppData\\Local\\relbench\\relbench\\Cache/rel-trial/db...\n",
      "Done in 9.41 seconds.\n",
      "Available tables:\n",
      "- conditions\n",
      "- conditions_studies\n",
      "- designs\n",
      "- drop_withdrawals\n",
      "- eligibilities\n",
      "- facilities\n",
      "- facilities_studies\n",
      "- interventions\n",
      "- interventions_studies\n",
      "- outcomes\n",
      "- outcome_analyses\n",
      "- reported_event_totals\n",
      "- sponsors\n",
      "- sponsors_studies\n",
      "- studies\n"
     ]
    }
   ],
   "source": [
    "# Load the rel-trial dataset\n",
    "dataset = get_dataset(\"rel-trial\", download=True)\n",
    "db = dataset.get_db()\n",
    "\n",
    "# Get all available tables\n",
    "tables = db.table_dict\n",
    "print(\"Available tables:\")\n",
    "for table_name in tables.keys():\n",
    "    print(f\"- {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing conditions...\n",
      "Exported 3973 rows to ..\\data\\conditions.csv\n",
      "\n",
      "Processing conditions_studies...\n",
      "Exported 408422 rows to ..\\data\\conditions_studies.csv\n",
      "\n",
      "Processing designs...\n",
      "Exported 249093 rows to ..\\data\\designs.csv\n",
      "\n",
      "Processing drop_withdrawals...\n",
      "Exported 381199 rows to ..\\data\\drop_withdrawals.csv\n",
      "\n",
      "Processing eligibilities...\n",
      "Exported 249730 rows to ..\\data\\eligibilities.csv\n",
      "\n",
      "Processing facilities...\n",
      "Exported 453233 rows to ..\\data\\facilities.csv\n",
      "\n",
      "Processing facilities_studies...\n",
      "Exported 1798765 rows to ..\\data\\facilities_studies.csv\n",
      "\n",
      "Processing interventions...\n",
      "Exported 3462 rows to ..\\data\\interventions.csv\n",
      "\n",
      "Processing interventions_studies...\n",
      "Exported 171771 rows to ..\\data\\interventions_studies.csv\n",
      "\n",
      "Processing outcomes...\n",
      "Exported 411933 rows to ..\\data\\outcomes.csv\n",
      "\n",
      "Processing outcome_analyses...\n",
      "Exported 225846 rows to ..\\data\\outcome_analyses.csv\n",
      "\n",
      "Processing reported_event_totals...\n",
      "Exported 383064 rows to ..\\data\\reported_event_totals.csv\n",
      "\n",
      "Processing sponsors...\n",
      "Exported 53241 rows to ..\\data\\sponsors.csv\n",
      "\n",
      "Processing sponsors_studies...\n",
      "Exported 391462 rows to ..\\data\\sponsors_studies.csv\n",
      "\n",
      "Processing studies...\n",
      "Exported 249730 rows to ..\\data\\studies.csv\n",
      "\n",
      "All tables exported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "data_dir = Path('../data')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export each table to CSV\n",
    "for table_name, table in tables.items():\n",
    "    print(f\"\\nProcessing {table_name}...\")\n",
    "    \n",
    "    # Get the dataframe\n",
    "    df = table.df\n",
    "    \n",
    "    # Basic processing\n",
    "    df.columns = df.columns.str.lower()  # Lowercase column names\n",
    "    \n",
    "    # Handle date columns\n",
    "    date_cols = [col for col in df.columns if 'date' in col.lower()]\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # Export to CSV\n",
    "    output_path = data_dir / f\"{table_name}.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Exported {len(df)} rows to {output_path}\")\n",
    "\n",
    "print(\"\\nAll tables exported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating exported files...\n",
      "\n",
      "conditions:\n",
      "- Rows: 3973\n",
      "- Columns: condition_id, mesh_term\n",
      "\n",
      "conditions_studies:\n",
      "- Rows: 408422\n",
      "- Columns: id, nct_id, condition_id, date\n",
      "\n",
      "designs:\n",
      "- Rows: 249093\n",
      "- Columns: id, nct_id, allocation, intervention_model, observational_model, primary_purpose, time_perspective, masking, masking_description, intervention_model_description, subject_masked, caregiver_masked, investigator_masked, outcomes_assessor_masked, date\n",
      "\n",
      "drop_withdrawals:\n",
      "- Rows: 381199\n",
      "- Columns: id, nct_id, period, reason, count, date\n",
      "\n",
      "eligibilities:\n",
      "- Rows: 249730\n",
      "- Columns: id, nct_id, sampling_method, gender, minimum_age, maximum_age, healthy_volunteers, population, criteria, gender_description, gender_based, adult, child, older_adult, date\n",
      "\n",
      "facilities:\n",
      "- Rows: 453233\n",
      "- Columns: facility_id, name, city, state, zip, country\n",
      "\n",
      "facilities_studies:\n",
      "- Rows: 1798765\n",
      "- Columns: id, nct_id, facility_id, date\n",
      "\n",
      "interventions:\n",
      "- Rows: 3462\n",
      "- Columns: intervention_id, mesh_term\n",
      "\n",
      "interventions_studies:\n",
      "- Rows: 171771\n",
      "- Columns: id, nct_id, intervention_id, date\n",
      "\n",
      "outcomes:\n",
      "- Rows: 411933\n",
      "- Columns: id, nct_id, outcome_type, title, description, time_frame, population, units, units_analyzed, dispersion_type, param_type, date\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anils\\AppData\\Local\\Temp\\ipykernel_2580\\3639938216.py:7: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome_analyses:\n",
      "- Rows: 225846\n",
      "- Columns: id, nct_id, outcome_id, non_inferiority_type, non_inferiority_description, param_type, param_value, dispersion_type, dispersion_value, p_value_modifier, p_value, ci_n_sides, ci_percent, ci_lower_limit, ci_upper_limit, ci_upper_limit_na_comment, p_value_description, method, method_description, estimate_description, groups_description, other_analysis_description, ci_upper_limit_raw, ci_lower_limit_raw, p_value_raw, date\n",
      "\n",
      "reported_event_totals:\n",
      "- Rows: 383064\n",
      "- Columns: id, nct_id, event_type, classification, subjects_affected, subjects_at_risk, date\n",
      "\n",
      "sponsors:\n",
      "- Rows: 53241\n",
      "- Columns: sponsor_id, name, agency_class\n",
      "\n",
      "sponsors_studies:\n",
      "- Rows: 391462\n",
      "- Columns: id, nct_id, sponsor_id, lead_or_collaborator, date\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anils\\AppData\\Local\\Temp\\ipykernel_2580\\3639938216.py:7: DtypeWarning: Columns (19,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studies:\n",
      "- Rows: 249730\n",
      "- Columns: nct_id, start_date, target_duration, study_type, acronym, baseline_population, brief_title, official_title, phase, enrollment, enrollment_type, source, limitations_and_caveats, number_of_arms, number_of_groups, has_dmc, is_fda_regulated_drug, is_fda_regulated_device, is_unapproved_device, is_ppsd, is_us_export, biospec_retention, biospec_description, source_class, baseline_type_units_analyzed, fdaaa801_violation, plan_to_share_ipd, detailed_descriptions, brief_summaries\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validate exports\n",
    "print(\"Validating exported files...\\n\")\n",
    "\n",
    "for table_name in tables.keys():\n",
    "    file_path = data_dir / f\"{table_name}.csv\"\n",
    "    if file_path.exists():\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"{table_name}:\")\n",
    "        print(f\"- Rows: {len(df)}\")\n",
    "        print(f\"- Columns: {', '.join(df.columns)}\\n\")\n",
    "    else:\n",
    "        print(f\"Warning: {table_name} file not found!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:semantic-gml]",
   "language": "python",
   "name": "conda-env-semantic-gml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
